\section{2}

How is the significance level related to Type I error? Why do we use hypothesis testing methods that start by assuming the null hypothesis is true instead of initially assuming the alternative is true?

\noindent\textbf{Answer:} 

The Type I error is directly controlled by the chosen significance level. To risk oversimplifying, they are basically the same thing. You can think of the significance level being a sliding point on a distribution where we decide how far out we need to go to decide to reject the null hypothesis. If we stay closer in, which has a large significance level, there's a higher chance we'll falsly reject the null. We don't need as much evidence, so there's more risk of a false rejection. Going further out requires data to be more extreme and more convincing for us to reject, giving us a lower Type I error.

As for the second part, I kind of answered it in Problem 1. However, a null distribution gives us something we can know for certain. $\theta = 5$ actually gives us a distribution we can examine and compare our data too. If we tried to assume $\theta \neq 5$ where do we start? There are infinitely many distributions that meet that criteria. We wouldn't be able to really do anything with that.
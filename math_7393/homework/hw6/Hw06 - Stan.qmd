---
title: "Homework 6 - Stan"
format: html
self-contained: true
---

```{r, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
#rstudioapi::restartSession(clean = TRUE)
```


```{r, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
packages <- c("ggplot2", "rstan", "coda", "bayesplot")

for (pkg in packages) {
  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
    install.packages(pkg, repos = "https://cran.rstudio.com/")
    library(pkg, character.only = TRUE)
  }
}

options(scipen = 20) # For fixing scientific notation nonsense
```

# Problem 1

Voter turnout has been a popular talking point in recent elections. To get a sense of voter turnout in Colorado, a national polling company contacted randomly selected registered Colorado voters until they reached 200 persons who said that they had voted. 303 persons said they had not voted, for a total sample size of 503. The response $y$ is the number of failures before getting the 200th registered voter who had voted. Thus, $y$ can be modeled as a negative binomial distribution with $n$ successes and probability of success $\theta$, where $\theta$ is the probability a registered voter stating they voted. 

Stan uses an alternative parameterization of the Negative Binomial distribution, where $y \mid n, \beta \sim \mathrm{Neg}\text{-}\mathrm{Bin}(n,\beta)$ has probability mass function
$$
p(y\mid n,\beta)=\binom{y+n-1}{n-1} \left(\frac{\beta}{\beta+1}\right)^n \left(\frac{1}{\theta+1}\right)^yI_{\{0,1,2\ldots\}}(y)I_{(0,\infty)}(\beta).
$$
In the parameterization above, the typical probability parameter $theta=\beta/(\beta+1)$. 

We will determine the posterior distribution for $\theta$ when the prior is $\theta\sim\mathrm{Beta(1.1, 1.5)}$.

## (a)

Use Stan to approximate the posterior distribution of $\theta$. Run 5 MCMC chains for at least 100,000 iterations. Discard the first half of each chain as warmup. Please provide your Stan model code in your answer to the problem.

**Solution**

```{r}
#| code-fold: true
#| code-summary: Stan model

stanmod = "
data {
  int<lower=1> n; // number of votes
  int<lower=0> y; // number of non-voters before nth vote
  real<lower=0> alpha; // prior parameters
  real<lower=0> beta; // prior parameters
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  y ~ neg_binomial(n, theta);  //data distribution
  theta ~ beta(alpha, beta); //prior distribution
}
generated quantities{
  int<lower=0> ytilde;
  ytilde = binomial_rng(n, theta);
}
"
```

```{r, results=FALSE}
#| code-fold: true
#| code-summary: Running the model

stan_dat <- list(n=200, y=303, alpha=1.1, beta=1.5)

# if compiled model doesn't already exist,
# compile the model, sample from model,
# returns object of class stan
# save model
if (!file.exists("voter_mod.rda")) {
  # compile and sample from model
  voter_fit = stan(model_code = stanmod,
                             data = stan_dat,
                             iter = 100000,
                             chains = 5)
  # alternatively, describe model
  voter_mod = stan_model(model_code = stanmod)
  save(voter_mod,
       file = "voter_mod.rda",
       compress = "xz")
} else {
    load(file = "voter_mod.rda")
    # draw samples from the model
    voter_fit = sampling(
        voter_mod, 
        data = stan_dat, 
        iter = 100000, 
        chains = 5
    )
}
```


## (b)

Provide a table containing (in order) the posterior mean, standard deviation, and the 0.025, 0.25, 0.50, 0.75, 0.975 quantiles for for $\theta$.

**Solution**

|Statistic | Mean	| SD	| 0.025	| 0.25	| 0.50	| 0.75	| 0.975|
|---|---|---|---|---|---|---|---|---|---|
$\theta$ | 0.663 | 0.060 | 0.552 | 0.621 |  0.660 | 0.701 | 0.787 |

```{r, echo=FALSE, include=FALSE}
# summary of voter_fit object (all_chains)
summary(voter_fit,
        pars = c("theta"),
        probs = c(0.025, 0.25, 0.50, 0.75, 0.975))$summary
```


# Problem 2

Suppose that you observe the realizations of a distribution with positive support stored in `y` (embedded in the qmd file but not shown for simplicity).

```{r}
#| code-fold: true
#| code-summary: Just the data

y <- c(3.3246186,  0.7155831,  2.1865298,
       1.7492273,  0.9324987,  5.4863425,
       2.7117632,  0.7926974,  1.1956440,
       3.2383931,  1.2987860,  0.9944326,
       0.5779083,  1.7695300,  1.0613076, 
       2.4900453,  2.4184646,  4.8643522,
       5.9443107,  3.9608494,  9.8182328, 
       0.8580478,  1.0733395,  0.7586947, 
       0.7647424,  1.3418217,  1.2706851,
       1.0757138,  1.3392547,  1.8848462,
       1.7100259,  8.1847849,  3.9656347,
       0.7385681,  1.3345326,  9.1610070,
       1.2966093,  2.8854925,  0.9075772, 
       0.5884744,  0.8074273,  1.3512495, 
       2.9246246,  1.5118090,  0.4647718,
       2.8645860,  2.6774785,  3.4369286,
       2.4903468,  2.7400405,  1.9198062, 
       0.7503989,  3.1689262,  2.3617032,
       1.4041014,  1.8026648,  1.1965619, 
       2.0051503,  2.5331624,  1.1123318, 
       2.0809009,  1.2085851,  2.4237742,
       3.0732074,  5.4937633,  2.1416139, 
       1.5527814,  1.2214949,  3.1004734, 
       2.0353448,  3.8491880,  2.2600403,
       4.7335075,  9.9232236,  0.9051508,
       1.1716122,  0.7579334,  7.0875481,
       2.9899513,  1.7808078,  0.9799685,
       1.3670716,  1.6737608,  1.0508578,
       12.0184742,  2.0558048,  3.8233638,
       1.4540376,  1.7876661,  2.2132504,
       0.7122299,  2.4231081,  4.6504884,
       2.0636710,  8.8337085,  0.4970524,
       1.5268181,  3.3103729,  0.9471728,
       0.7164088)
```

We will model the data as $y \mid \alpha, \beta \sim \mathrm{Inv}\text{-}\mathrm{Gamma}(\alpha, \beta)$. 

We will use the prior distributions $\alpha \sim U(1, 5)$ and $\beta \sim \mathrm{Gamma}(4, 4)$.

## (a)

Plot the estimated density of $y$.

**Solution**

```{r}
y |> 
    density() |> 
    plot(
        main = "Estimated Density of y",
        xlab = "y"
    )
```


## (b)

Use Stan to approximate the posterior distributions of $\alpha$ and $\beta$. Run 5 MCMC chains for at least 100,000 iterations. Discard the first half of each chain as warmup. Please provide your Stan model code in your answer to the problem.

**Solution**

```{r}
#| code-fold: true
#| code-summary: Stan model

stanmod = "
data {
  int<lower=0> N;           // sample size
  real<lower=0> y[N];       // the data
  real<lower=0> low;        // lower bound for theta_1 prior
  real<lower=0> up;         // upper bound for theta_1 prior
  real<lower=0> alpha;      // shape parameter for theta_2 prior
  real<lower=0> beta;       // scale parameter for theta_2 prior
}
parameters {
  real<lower=0> theta_1;    // alpha param of y
  real<lower=0> theta_2;    // beta param of y
}
model {
  y ~ inv_gamma(theta_1, theta_2);      //data distribution
  theta_1 ~ uniform(low, up);           //prior distribution for alpha
  theta_2 ~ gamma(alpha, beta);         //prior distribution for beta
}
generated quantities{
  real<lower=0> ytilde;
  ytilde = inv_gamma_rng(theta_1, theta_2);
}
"
```

```{r, results=FALSE}
#| code-fold: true
#| code-summary: Running the model

stan_dat <- list(N=length(y), y=y, low=1, up=5, alpha=4, beta=4)

# if compiled model doesn't already exist,
# compile the model, sample from model,
# returns object of class stan
# save model
if (!file.exists("inv_gamma_mod.rda")) {
  # compile and sample from model
  inv_gamma_fit = stan(model_code = stanmod,
                             data = stan_dat,
                             iter = 100000,
                             chains = 5)
  # alternatively, describe model
  inv_gamma_mod = stan_model(model_code = stanmod)
  save(inv_gamma_mod,
       file = "inv_gamma_mod.rda",
       compress = "xz")
} else {
    load(file = "inv_gamma_mod.rda")
    # draw samples from the model
    inv_gamma_fit = sampling(
        inv_gamma_mod, 
        data = stan_dat, 
        iter = 100000, 
        chains = 5
    )
}
```

## (c)

Provide a table containing (in order) the posterior mean, standard deviation, and the 0.025, 0.25, 0.50, 0.75, 0.975 quantiles for $\alpha$ and $\beta$.

|Statistic | Mean	| SD	| 0.025	| 0.25	| 0.50	| 0.75	| 0.975|
|---|---|---|---|---|---|---|---|---|---|
$\alpha$ | 2.01 | 0.255 | 1.55 | 1.84 | 2.00 | 2.18 | 2.54 |
$\beta$ | 2.92 | 0.415 | 2.16 | 2.63 | 2.90 | 3.18 | 3.78 |

**Solution**

```{r, include=FALSE}
summary(
    inv_gamma_fit,
    pars = c("theta_1", "theta_2"),
    probs = c(0.025, 0.25, 0.50, 0.75, 0.975)
)$summary
```


# Problem 3

Consider the data in `yc`, which contains counts for the number of coal mine disasters over a 112-year period (1851 to 1962) in the United Kingdom. The data have relatively high disaster counts in the early era, and relatively low counts in the later era. How did technology improvements and safety practices have an actual effect on the rate of serious accidents?

Assume that $y_1,y_2,\ldots,y_{40} \mid \lambda, \stackrel{i.i.d.}{\sim} \mathrm{Poisson}(\lambda)$ and $y_{41},y_{42},\ldots,y_{112}\mid \phi \stackrel{i.i.d.}{\sim} \mathrm{Poisson}(\phi)$. 
In this model, a change in the rate of serious coal mine accidents occurs in the 41st year because because of technology and/or safety improvements. Our interest lies in finding the posterior distributions for $\lambda$ and $\phi$. Assume a Gamma(4, 1) prior distribution for $\lambda$ and a Gamma(1, 2) prior distribution for $\phi$.  

## (a)

Use Stan to approximate the posterior distributions of $\lambda$ and $\phi$. Run 5 MCMC chains for at least 100,000 iterations. Discard the first half of each chain as warmup. Please provide your Stan model code in your answer to the problem.

**Solution**

```{r}
#| code-fold: true
#| code-summary: Just the data
#| 
yc <- c(
4, 5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1)
```

```{r}
#| code-fold: true
#| code-summary: Stan model

stanmod = "
data {
  int<lower=0> N;               // total sample size
  int<lower=0> N_pre;           // sample size for first chunk
  int<lower=0> N_post;          // sample size for second chunk
  int<lower=0> y_pre[N_pre];    // the data before the shift
  int<lower=0> y_post[N_post];  // the data after the shift
  real<lower=0> alpha_lambda;   // lambda shape prior
  real<lower=0> beta_lambda;    // lambda rate prior
  real<lower=0> alpha_phi;      // phi shape prior
  real<lower=0> beta_phi;       // phi rate prior
}
parameters {
  real<lower=0> lambda;     // param for y_pre
  real<lower=0> phi;        // param for y_post
}
model {
  y_pre ~ poisson(lambda);                      //data distribution 1
  y_post ~ poisson(phi);                        //data distribution 2
  lambda ~ gamma(alpha_lambda, beta_lambda);    //prior distribution 1
  phi ~ gamma(alpha_phi, beta_phi);             //prior distribution 2
}
generated quantities{
    vector[N] yrep;
    for (j in 1:N_pre) {
        yrep[j] = poisson_rng(lambda);
    }
    for (j in (N_pre + 1):N) {
        yrep[j] = poisson_rng(phi);
    }
}
"
```


```{r, results=FALSE}
#| code-fold: true
#| code-summary: Running the model
#| 
yc_pre <- yc[1:40]
yc_post <- yc[41:length(yc)]

stan_dat <- list(
    N=length(yc),
    N_pre=length(yc_pre), 
    N_post=length(yc_post),
    y_pre=yc_pre,
    y_post=yc_post,
    alpha_lambda=4,
    beta_lambda=1,
    alpha_phi=1,
    beta_phi=2
)

# if compiled model doesn't already exist,
# compile the model, sample from model,
# returns object of class stan
# save model
if (!file.exists("coal_mod.rda")) {
  # compile and sample from model
  coal_fit = stan(model_code = stanmod,
                             data = stan_dat,
                             iter = 100000,
                             chains = 5)
  # alternatively, describe model
  coal_mod = stan_model(model_code = stanmod)
  save(coal_mod,
       file = "coal_mod.rda",
       compress = "xz")
} else {
    load(file = "coal_mod.rda")
    # draw samples from the model
    coal_fit = sampling(
        coal_mod, 
        data = stan_dat, 
        iter = 100000, 
        chains = 5
    )
}
```

## (b)

Provide a table containing (in order) the posterior mean, standard deviation, and the 0.025, 0.25, 0.50, 0.75, 0.975 quantiles for $\lambda$ and $\phi$.

**Solution**

|Statistic | Mean	| SD	| 0.025	| 0.25	| 0.50	| 0.75	| 0.975|
|---|---|---|---|---|---|---|---|---|---|
$\lambda$ | 3.15 | 0.28 | 2.63 | 3.00 | 3.14 | 3.32 | 3.71 |
$\phi$ | 0.91 | 0.11 | 0.70 | 0.83 | 0.90 | 0.98 | 1.13 |



```{r, include=FALSE}
summary(
    coal_fit,
    pars = c("lambda", "phi"),
    probs = c(0.025, 0.25, 0.50, 0.75, 0.975)
)$summary
```

## (c)

Explain why the central posterior intervals for $\lambda$ and $\phi$ are narrower in this homework than in Homework 4.

**Solution**

There's a random element removed. In homework 4 we were trying to ascertain $k$. In this problem we provide it. 

## (d)

Similar to the examples from class, generate replications of `yc` (`yrep`) from the posterior predictive distribution.  Create a histogram comparing the observed data to 8 of the replicated data sets. How do the replicated samples compare?

**Solution**

Important thing here, my rstan code generates a new 112 element sample for every non-warmup iteration. So with 5 chains that gives us $100000*5/2 = 250000$ sampled vectors. We wanna pull out 8 of these at random to check.

```{r}
yrep = extract(coal_fit, "yrep")$yrep
# This gives us 8 random indices to keep.
subset_indices <- sample(nrow(yrep), 8)
yrep <- yrep[subset_indices, ]
```

```{r}
bins = yc |> length() |> sqrt() |> round()
ppc_hist(yc, yrep, bins=bins)
```

These honestly look really good! A little extra density at the tail, but really not too shabby. 
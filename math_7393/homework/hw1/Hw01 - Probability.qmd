---
title: "Homework 1 - Probability"
format: html
self-contained: true
author: Brady Lamson
date: 1/29/2025
toc: true
---

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
library(glue)
```


# Problem 1

Suppose that if $\theta = 1$, then $y \sim N(5, 2^2)$. If $\theta=2$, then $y \sim \chi_3^2$. Assume $P(\theta=1)=0.3$ and $P(\theta=2)=0.7$.

## Part A

**Problem:** Determine the marginal density of $y$ using the law of total probability. We want to find $p(y)$ while knowing $p(y \mid \theta = 1)$ and $p(y\mid \theta = 2)$.

Setup

$$
\begin{aligned}
    p(y \mid \theta=1) &= N(\mu = 5, \sigma = 2) \\
    &= \frac{1}{\sqrt{2\pi}2} \cdot exp\left( -\frac{(y-5)^2}{2 \cdot 2^2} \right) \\
    p(y \mid \theta=2) &= \chi^2_{v=3} \\
    &= \frac{2^{-3/2}}{\Gamma(3/2)} y^{(3/2) - 1}e^{-y/2} \;;\; y>0
\end{aligned}
$$

Marginal Density

$$
\begin{aligned}
    p(y) &= p(y\mid\theta=1) \cdot p(\theta=1) + p(y\mid\theta=2) \cdot p(\theta=2) \\
    &= \left( 0.3 \cdot \frac{1}{\sqrt{2\pi}2} \cdot exp\left( -\frac{(y-5)^2}{2 \cdot 2^2} \right) \right) +
        \left( 0.7 \cdot \frac{2^{-3/2}}{\Gamma(3/2)} y^{(3/2) - 1}e^{-y/2} \right)
\end{aligned}
$$

## Part B

**Problem:** Plot the marginal density of $y$.

```{r, echo=FALSE, warning=FALSE}
# Define the normal density function (y | theta = 1)
p_y_given_theta1 <- function(y) {
    mu <- 5
    sigma <- 2
    (1 / (sqrt(2 * pi) * sigma)) * exp(-((y - mu)^2) / (2 * sigma^2))
}

# Define the chi-squared density function (y | theta = 2)
p_y_given_theta2 <- function(y) {
     k <- 3  # Degrees of freedom
    (1 / (2^(k / 2) * gamma(k / 2))) * y^((k / 2) - 1) * exp(-y / 2)
}

# Define the marginal density p(y)
p_y <- function(y) {
  p_theta1 <- 0.3  # P(theta = 1)
  p_theta2 <- 0.7  # P(theta = 2)
  p_theta1 * p_y_given_theta1(y) + p_theta2 * p_y_given_theta2(y)
}

curve(p_y, from = 0, to = 15, ylab = "p(y)", xlab="y", main="Marginal Density of y")
```


## Part C

**Problem:** Determine $P(\theta=1 \mid y=0.5)$.

$$
\begin{aligned}
    P(\theta=1 \mid y=0.5) &= \frac{p(y=0.5 \mid \theta=1) p(\theta = 1)}{p(y=0.5)}
\end{aligned}
$$
For this I can automatically calculate these values using the functions I wrote to create the plot. 

```{r}
numerator_piece <- p_y_given_theta1(0.5)
denominator <- p_y(0.5)
p_theta_1 <- 0.3
result <- numerator_piece * p_theta_1 / denominator
```

```{r, echo=FALSE}
glue("
     p(y=0.5 given that theta=1):   {numerator_piece |> round(5)}
     p(theta=1):                    {p_theta_1}
     p(y=0.5):                      {denominator |> round(5)}
     p(theta=1 given that y=0.5):   {result |> round(5)}
")
```

# Problem 2

Suppose there are two species of panda bear. Both are equally common in the wild and live in the same places. They look exactly alike and eat the same food, and there is yet no genetic assay capable of telling them apart. They differ however in their family sizes. Species A gives birth to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birthing singleton infants. Assume these numbers are known with certainty, from many years of field research.

## Part A
**Problem:**  What are the prior probabilities for each type of panda?

As the two species are equally common in the wild we can keep our priors simple.

Let us have species A and B.

$p(\theta=A) = p(\theta=B) = 0.5$

## Part B
**Problem:** You observe a female panda of unknown species give birth to twins (with no other information). What is the probability that the female panda is species A?

Here we can do a lot of setup to make things easier for us down the line. 

### Likelihood Functions

We'll set up our likelihood functions as bernoulli random variables.

$$
\begin{align}
    p(y\mid\theta=A) &= 0.1^y(0.9)^{1-y} \\
    p(y\mid\theta=B) &= 0.2^y(0.8)^{1-y}
\end{align}
$$

In other words:

$$
\begin{align}
    p(y=1\mid\theta=A) &= 0.1 \\
    p(y=2\mid\theta=A) &= 0.9 \\
    p(y=1\mid\theta=B) &= 0.2 \\
    p(y=1\mid\theta=B) &= 0.8
\end{align}
$$

### Marginal Distribution

$$
\begin{align}
    p(y) &= p(y\mid\theta=A) p(\theta=A) + p(y\mid\theta=B) p(\theta=B) \\
    &= (0.1^y(0.9)^{1-y} \cdot 0.5) + (0.2^y(0.8)^{1-y} \cdot 0.5)
\end{align}
$$

### Solution

$$
\begin{align}
    p(\theta=A \mid y=1) &= \frac{p(y=1 | \theta=A) \cdot p(\theta=A)}{p(y=1)} \\
    &= \frac{0.1^1(0.9)^{1-1} \cdot 0.5}{(0.1^1(0.9)^{1-1} \cdot 0.5) + (0.2^1(0.8)^{1-1} \cdot 0.5)} \\
    &= \frac{0.05}{0.05+0.1} \\
    &= \frac{1}{3}
\end{align}
$$

## Part C
**Problem:**  Assume the same female panda is about to give birth a second time. What is probability the second birth is also twins?

Our goal here is to find $p(y_2=1 | y_1=1)$. This uses the **posterior predictive distribution**. Thankfully this is actually quite easy for us to set up. 

Referring back to the notes for a moment:

$p(\tilde{y} | y) = \int p(\tilde{y} \mid \theta)p(\theta\mid y) d\theta$

Essentially, we use our posterior distribution from part b to scale the probability that we got our new result. 

For our discrete problem we can write this as follows:

$$
\begin{align}
    p(y_2 = 1 | y_1 = 1) &= \left(p(y_2 = 1 |\theta=A)) \cdot p(\theta=A | y_1=1)\right) 
    + \left(p(y_2 = 1 |\theta=B)) \cdot p(\theta=B | y_1=1)\right) \\
    &= \left(0.1 \cdot \frac{1}{3} + 0.2 \cdot \frac{2}{3} \right) \\
    &= \frac{1}{6}
\end{align}
$$

## Part D
**Problem:**  Assume the female pandaâ€™s second birth is a singleton panda. In light of the two births (twins, then singleton), what is the probability that the female panda is species A?

Goal: Find $p(\theta=A | y_1=1, y_2=0)$. 

$$
\begin{align}
    p(\theta=A | y_1=1, y_2=0) &= \frac{p(y_2=0|\theta=A) \cdot p(\theta=A | y_1=1)}
    {(p(y_2=0|\theta=A) \cdot p(\theta=A | y_1=1)) + (p(y_2=0|\theta=B) \cdot p(\theta=B | y_1=1))} \\
    &= \frac{0.9 \cdot \frac{1}{3}}{\left( 0.9 \cdot \frac{1}{3}\right) + \left( 0.8 \cdot \frac{2}{3}\right)} \\
    &= \frac{\frac{9}{30}}{\frac{9}{30} + \frac{16}{30}} \\
    &= \frac{9}{25} \\
    &= 0.36
\end{align}
$$

# Problem 3 (Monty Hall)

Suppose you're on a game show, and you're asked to select a prize behind one of three doors: behind one door is a car; behind the other doors are goats. You pick a door. The host, who knows what's behind the doors, always opens a door that has a goat behind it. The host then says to you, "Do you want to switch your choice to the other unopened door?"

Determine the probability of winning the car when using the strategy of always switching doors when the host gives you the opportunity. Note that we are not treating the switching strategy as a random event. The key to simplifying this problem is determining what event to condition on.

## Thoughts

Let's think through the order of operations.

1. We pick a door that may/may not hold the car.
2. Monte opens a door with a goat.
3. We always swap

### Outcomes

**A**

1. We pick the door with the car
2. 2 goats remain, Monte removes 1.
3. We swap to a goat. **(Failure)**

**B**

1. We pick the door with the goat.
2. 1 goat remains, Monte removes it.
3. We swap to a car. **(Success)**

What outcome we get is entirely determined by what door we choose initially. Choosing a goat is the only way we win given that we always swap.

Let's treat our initial pick as a bernoulli. We have a $1/3$ chance of choosing a car and a $2/3$ chance of choosing a goat. If we choose the goat we win. So, my thought is that our chance of success given that we always swap is $2/3$. I'm not sure how to put that in conditional probability terms though. 

## Bayesian Solution

To think of this in the conditional way, let us frame the problem this way. What is the probability we win a car given that we selected a door with a car (or goat)?

Let $\theta$ here repsent what was behind the door we chose, either a goat or a car. We'll represent those with $g$ and $c$ respectively. Then, $y$ will represent the outcome. We'll use the same notation for $y$. 

Since we always swap, $\theta=g$ always results in a win, and, by extension, $\theta=c$ always results in a loss. We have a $2/3$ of choosing a goat initially, and a $1-(2/3)=1/3$ chance of choosing a car.

So,

$$
\begin{align}
   p(y=c \mid \theta=g) = 1 \\
   p(y=c \mid \theta=c) = 0 \\
   p(\theta = g) = \frac{2}{3} \\
   p(\theta = c) = \frac{1}{3} \\
\end{align}
$$

From here, we just use the law of total probability! This is the marginal distribution of $y$ as it represents the probability that we win a car given that we always swap. 

$$
\begin{align}
    p(y) &= p(y=c \mid \theta=g) \cdot p(\theta = g) + p(y=c \mid \theta=c) \cdot p(\theta = c) \\
    &= 1 \cdot \frac{2}{3} + 0 \cdot \frac{1}{3} \\
    &= \frac{2}{3}
\end{align}
$$